{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to FedImpute FedImpute is a benchmarking and evaluation tool to assess the effectiveness of federated imputation across various missing data scenarios. Installation Install python >= 3.8.0 python -m venv ./venv # window gitbash source ./venv/Scripts/activate # linux/unix source ./venv/bin/activate Install the required packages pip install -r requirements.txt Basic Usage Step 1. Prepare Data import numpy as np data = np.random.rand(10000, 10) data_config = { 'task_type': 'regression', 'num_cols': 9, } Step 2. Simulate Federated Missing Data Scenario from fedimpute.simulator import Simulator simulator = Simulator() simulation_results = simulator.simulate_scenario( data, data_config, num_clients = 10, dp_strategy='iid-even', ms_mech_type='mcar', verbose=1 ) Step 3. Execute Federated Imputation Algorithms from fedimpute.execution_environment import FedImputeEnv env = FedImputeEnv() env.configuration(imputer = 'gain', fed_strategy='fedavg', fit_mode = 'fed') env.setup_from_simulator(simulator = simulator, verbose=1) env.run_fed_imputation() Step 4. Evaluate imputation outcomes from fedimpute.evaluation import Evaluator evaluator = Evaluator() evaluator.evaluate(env, ['imp_quality', 'pred_downstream_local', 'pred_downstream_fed']) evaluator.show_results()","title":"Home"},{"location":"#welcome-to-fedimpute","text":"FedImpute is a benchmarking and evaluation tool to assess the effectiveness of federated imputation across various missing data scenarios.","title":"Welcome to FedImpute"},{"location":"#installation","text":"Install python >= 3.8.0 python -m venv ./venv # window gitbash source ./venv/Scripts/activate # linux/unix source ./venv/bin/activate Install the required packages pip install -r requirements.txt","title":"Installation"},{"location":"#basic-usage","text":"","title":"Basic Usage"},{"location":"#step-1-prepare-data","text":"import numpy as np data = np.random.rand(10000, 10) data_config = { 'task_type': 'regression', 'num_cols': 9, }","title":"Step 1. Prepare Data"},{"location":"#step-2-simulate-federated-missing-data-scenario","text":"from fedimpute.simulator import Simulator simulator = Simulator() simulation_results = simulator.simulate_scenario( data, data_config, num_clients = 10, dp_strategy='iid-even', ms_mech_type='mcar', verbose=1 )","title":"Step 2. Simulate Federated Missing Data Scenario"},{"location":"#step-3-execute-federated-imputation-algorithms","text":"from fedimpute.execution_environment import FedImputeEnv env = FedImputeEnv() env.configuration(imputer = 'gain', fed_strategy='fedavg', fit_mode = 'fed') env.setup_from_simulator(simulator = simulator, verbose=1) env.run_fed_imputation()","title":"Step 3. Execute Federated Imputation Algorithms"},{"location":"#step-4-evaluate-imputation-outcomes","text":"from fedimpute.evaluation import Evaluator evaluator = Evaluator() evaluator.evaluate(env, ['imp_quality', 'pred_downstream_local', 'pred_downstream_fed']) evaluator.show_results()","title":"Step 4. Evaluate imputation outcomes"},{"location":"about/","text":"Arbor mecum nostro Rhesi Illic spumam Lorem markdownum India exarsit ignibus aequoris Titan et postera vates: corpus, poenae inque. Ut arce, motu, dispar traiecit Lacinia tamen . Fudi vix non membra heros. Lyciae erat nudorum media, dei vicit dolorem frustra leni aequor at concita soror monstris manumque vulnus. Silvis optabat . Incepti de currus, cum urit sperato poenas sine, fata matris aliisque tellurem visum Cycno nupta. Fatigatum aestus! Est niveo serpentem sit Quoque Troum. Sermone et nunc tot credite aequem meri quam tutos, peti stravere, gregibus novavit et. Mihi Iuppiter mirabile, quo grave furibunda nunc gemitus, guttura Patraeque funeris favilla. Flores Triptolemus Matri. var pda_postscript_dma = postscript_cmos_mail(office.monochrome(46), koffice_ascii, mailItunes); node += cable_bezel_menu; if (powerFatAtm.clipboard_text_vertical.bccKvmLeaf(dmaOverwriteAscii, plain) + passiveCameraWaveform(462879)) { gateway = multicasting(drive, hubMashupAvatar.floppy_zero_qwerty.rom_linux_log(digital, dllDebug, 2)); } Sit est ternisque inter Tamen illis sedare Frigus; natalis rege isset dilaniat auras. Vero deam premis habitat hinc sternuntur meritus pedum et cum. Lemnius crescentemque lugebere flere os illic quamquam facto dextera quae tantum color vestes hoc veniunt magnus quiete: et. Erunt rudis et dolor trahat Philoctete tormentis Atlas Iphide partibus! Cycnum abiit lunae fuit defendere mutantur quadriiugo neci; fui unum, Cycnum agebat? Pater illa ergo virgae lapidumque domitos, sororis tu mitior carmina innixus: confusa sumus. Si et, maerentes ortas Daedalon tectoque genitor famuli. Enim paventem armis dignus vis instructo usque animoque, ignara aper iter est campus laceris in iniecit Oileos. In tepido tamen: artus illa ramisque desinite aures, diversae? Promptum fuit accessit ambiguum querulas consenuere, te alii herbas vox conplexusque. Aestuat mihi opes miser, ratis, circumdata aurum. Hunc mihi exiguas gelidis ab faciem, et Ceyx draconibus, Corythumque diversa, alis Priapi.","title":"Arbor mecum nostro Rhesi"},{"location":"about/#arbor-mecum-nostro-rhesi","text":"","title":"Arbor mecum nostro Rhesi"},{"location":"about/#illic-spumam","text":"Lorem markdownum India exarsit ignibus aequoris Titan et postera vates: corpus, poenae inque. Ut arce, motu, dispar traiecit Lacinia tamen . Fudi vix non membra heros. Lyciae erat nudorum media, dei vicit dolorem frustra leni aequor at concita soror monstris manumque vulnus. Silvis optabat . Incepti de currus, cum urit sperato poenas sine, fata matris aliisque tellurem visum Cycno nupta. Fatigatum aestus!","title":"Illic spumam"},{"location":"about/#est-niveo-serpentem-sit","text":"Quoque Troum. Sermone et nunc tot credite aequem meri quam tutos, peti stravere, gregibus novavit et. Mihi Iuppiter mirabile, quo grave furibunda nunc gemitus, guttura Patraeque funeris favilla. Flores Triptolemus Matri. var pda_postscript_dma = postscript_cmos_mail(office.monochrome(46), koffice_ascii, mailItunes); node += cable_bezel_menu; if (powerFatAtm.clipboard_text_vertical.bccKvmLeaf(dmaOverwriteAscii, plain) + passiveCameraWaveform(462879)) { gateway = multicasting(drive, hubMashupAvatar.floppy_zero_qwerty.rom_linux_log(digital, dllDebug, 2)); }","title":"Est niveo serpentem sit"},{"location":"about/#sit-est-ternisque-inter","text":"Tamen illis sedare Frigus; natalis rege isset dilaniat auras. Vero deam premis habitat hinc sternuntur meritus pedum et cum. Lemnius crescentemque lugebere flere os illic quamquam facto dextera quae tantum color vestes hoc veniunt magnus quiete: et. Erunt rudis et dolor trahat Philoctete tormentis Atlas Iphide partibus! Cycnum abiit lunae fuit defendere mutantur quadriiugo neci; fui unum, Cycnum agebat? Pater illa ergo virgae lapidumque domitos, sororis tu mitior carmina innixus: confusa sumus. Si et, maerentes ortas Daedalon tectoque genitor famuli. Enim paventem armis dignus vis instructo usque animoque, ignara aper iter est campus laceris in iniecit Oileos. In tepido tamen: artus illa ramisque desinite aures, diversae? Promptum fuit accessit ambiguum querulas consenuere, te alii herbas vox conplexusque. Aestuat mihi opes miser, ratis, circumdata aurum. Hunc mihi exiguas gelidis ab faciem, et Ceyx draconibus, Corythumque diversa, alis Priapi.","title":"Sit est ternisque inter"},{"location":"get_started/","text":"Installation Install python >= 3.8.0 python -m venv ./venv # window gitbash source ./venv/Scripts/activate # linux/unix source ./venv/bin/activate Install the required packages pip install -r requirements.txt Basic Usage Step 1. Prepare Data import numpy as np data = np.random.rand(10000, 10) data_config = { 'task_type': 'regression', 'num_cols': 9, } Step 2. Simulate Federated Missing Data Scenario from fedimpute.simulator import Simulator simulator = Simulator() simulation_results = simulator.simulate_scenario( data, data_config, num_clients = 10, dp_strategy='iid-even', ms_mech_type='mcar', verbose=1 ) Step 3. Execute Federated Imputation Algorithms from fedimpute.execution_environment import FedImputeEnv env = FedImputeEnv() env.configuration(imputer = 'gain', fed_strategy='fedavg', fit_mode = 'fed') env.setup_from_simulator(simulator = simulator, verbose=1) env.run_fed_imputation() Step 4. Evaluate imputation outcomes from fedimpute.evaluation import Evaluator evaluator = Evaluator() evaluator.evaluate(env, ['imp_quality', 'pred_downstream_local', 'pred_downstream_fed']) evaluator.show_results()","title":"Install & Basic Usage"},{"location":"get_started/#installation","text":"Install python >= 3.8.0 python -m venv ./venv # window gitbash source ./venv/Scripts/activate # linux/unix source ./venv/bin/activate Install the required packages pip install -r requirements.txt","title":"Installation"},{"location":"get_started/#basic-usage","text":"","title":"Basic Usage"},{"location":"get_started/#step-1-prepare-data","text":"import numpy as np data = np.random.rand(10000, 10) data_config = { 'task_type': 'regression', 'num_cols': 9, }","title":"Step 1. Prepare Data"},{"location":"get_started/#step-2-simulate-federated-missing-data-scenario","text":"from fedimpute.simulator import Simulator simulator = Simulator() simulation_results = simulator.simulate_scenario( data, data_config, num_clients = 10, dp_strategy='iid-even', ms_mech_type='mcar', verbose=1 )","title":"Step 2. Simulate Federated Missing Data Scenario"},{"location":"get_started/#step-3-execute-federated-imputation-algorithms","text":"from fedimpute.execution_environment import FedImputeEnv env = FedImputeEnv() env.configuration(imputer = 'gain', fed_strategy='fedavg', fit_mode = 'fed') env.setup_from_simulator(simulator = simulator, verbose=1) env.run_fed_imputation()","title":"Step 3. Execute Federated Imputation Algorithms"},{"location":"get_started/#step-4-evaluate-imputation-outcomes","text":"from fedimpute.evaluation import Evaluator evaluator = Evaluator() evaluator.evaluate(env, ['imp_quality', 'pred_downstream_local', 'pred_downstream_fed']) evaluator.show_results()","title":"Step 4. Evaluate imputation outcomes"},{"location":"overview/","text":"Overview of FedImpute FedImpute is an open-source Python package designed to facilitate the simulation, imputation and evaluation of missing data in federated learning environments. By leveraging advanced statistical and machine learning imputation techniques, FedImpute enables collaborative data imputation under federated data scenario. This package is ideal for researchers and practitioners working with decentralized datasets with missing data and care about how to design and evaluate the state-of-art missing data imputation method under federated learning evironment. Understanding Missing Data in Horizontal Federated Learning Missing data occurs when <NA> data value is stored for a variable in an observation within a dataset. In data analysis, missing data can significantly impact the quality of insights and the performance of predictive models. The causes of missing data can vary widely, including data entry errors, non-response in surveys, or interruptions in data collection. It's crucial to address these gaps effectively, as improper handling can lead to biased estimates and incorrect conclusions. Types of Missing Data Missing data can be categorized into three types, each with its own implications for data analysis: Missing Completely at Random (MCAR) : The probability of a data point being missing is the arbitary random. Missing at Random (MAR) : The probability of a data point being missing is related to other observed variables, but not to the missing data itself. Missing Not at Random (MNAR) : The probability of a data point being missing is related to the reason it is missing. For more information on missing data, refer to the Missing Data Introduction . Missing Data Under Federated Learning Scenario Horizontal federated learning (HFL) involves a scenario where multiple parties, each with their own datasets. These datasets often have the same feature space but different observations. Usually, a common case of HFL is when the data is distributed across multiple silos, for example, hospitals, banks, or research institutions. In these scenarios, missing data can be a significant challenge, as for these common application domains such as healthcare, the missing data is very prevalent. The missing data scenario under these scenarios can be further complex, because of the following dimensions: Missing Mechanism Diversity . Missing values in the data can occur due to different reasons and are modeled through missing mechanisms, which are categorized into three distinct types depending upon how the missing values are related to the data. Missing Mechanism Heterogeneity . Missing values in the same feature can be due to different missing mechanisms across silos. Data Heterogeneity . The data across silos can be non-iid to varying degrees. Missing Data Imputation of Federated Datasets A common approach to handling missing data is imputation, where missing values are estimated based on the observed data. More details of imputation methods and their performance can be found in the How to deal with missing values? , Imputation Book , Hyperimpute . Under HFL, effective strategies for handling missing data must consider how to unify the decentralized or local imputation techniques, where each party performed independently. By using common federated learning solutions to allow for collaborative imputation without exposing individual data points, we call it Federated Imputation . Due to the reason of the complexity of the problem, it is important to have a benchmarking tool to rapidly evaluate the performance of federated imputation algorithms under different missing data scenarios. FedImpute is designed to address this need. Features of FedImpute Flexible Missing Data Simulation : Provide flexible API to simulate missing data scenarios under various missing data distribution and data partition strategies. Built-in Federated Imputation Methods : Supports multiple imputation techniques, including mean, and model-based approaches, tailored for distributed data. Easy Integration : Designed to be easily extended with federated imputation algorithms and workflows. Customizability : Offers extensive configuration options to adapt the imputation process to specific needs. Architecture and Components FedImpute is built on top of the following components: Federated Missing Data Scenario Simulation , Federated Imputation Execution Environment , and Evaluation . Federated Missing Data Scenario Simulation : This component simulates missing data scenarios under various missing data distribution and data partition strategies. Federated Imputation Execution Environment : This component executes federated imputation algorithms on the simulated missing data scenarios. Evaluation : This component evaluates the imputation outcomes and provides insights into the performance of the imputation algorithms. License FedImpute is released under the GPL v3.0 License, allowing free use, modification, and distribution of the software. This license encourages open collaboration by permitting the incorporation of this package into both open and closed-source projects.","title":"Overview of FedImpute"},{"location":"overview/#overview-of-fedimpute","text":"FedImpute is an open-source Python package designed to facilitate the simulation, imputation and evaluation of missing data in federated learning environments. By leveraging advanced statistical and machine learning imputation techniques, FedImpute enables collaborative data imputation under federated data scenario. This package is ideal for researchers and practitioners working with decentralized datasets with missing data and care about how to design and evaluate the state-of-art missing data imputation method under federated learning evironment.","title":"Overview of FedImpute"},{"location":"overview/#understanding-missing-data-in-horizontal-federated-learning","text":"Missing data occurs when <NA> data value is stored for a variable in an observation within a dataset. In data analysis, missing data can significantly impact the quality of insights and the performance of predictive models. The causes of missing data can vary widely, including data entry errors, non-response in surveys, or interruptions in data collection. It's crucial to address these gaps effectively, as improper handling can lead to biased estimates and incorrect conclusions.","title":"Understanding Missing Data in Horizontal Federated Learning"},{"location":"overview/#types-of-missing-data","text":"Missing data can be categorized into three types, each with its own implications for data analysis: Missing Completely at Random (MCAR) : The probability of a data point being missing is the arbitary random. Missing at Random (MAR) : The probability of a data point being missing is related to other observed variables, but not to the missing data itself. Missing Not at Random (MNAR) : The probability of a data point being missing is related to the reason it is missing. For more information on missing data, refer to the Missing Data Introduction .","title":"Types of Missing Data"},{"location":"overview/#missing-data-under-federated-learning-scenario","text":"Horizontal federated learning (HFL) involves a scenario where multiple parties, each with their own datasets. These datasets often have the same feature space but different observations. Usually, a common case of HFL is when the data is distributed across multiple silos, for example, hospitals, banks, or research institutions. In these scenarios, missing data can be a significant challenge, as for these common application domains such as healthcare, the missing data is very prevalent. The missing data scenario under these scenarios can be further complex, because of the following dimensions: Missing Mechanism Diversity . Missing values in the data can occur due to different reasons and are modeled through missing mechanisms, which are categorized into three distinct types depending upon how the missing values are related to the data. Missing Mechanism Heterogeneity . Missing values in the same feature can be due to different missing mechanisms across silos. Data Heterogeneity . The data across silos can be non-iid to varying degrees.","title":"Missing Data Under Federated Learning Scenario"},{"location":"overview/#missing-data-imputation-of-federated-datasets","text":"A common approach to handling missing data is imputation, where missing values are estimated based on the observed data. More details of imputation methods and their performance can be found in the How to deal with missing values? , Imputation Book , Hyperimpute . Under HFL, effective strategies for handling missing data must consider how to unify the decentralized or local imputation techniques, where each party performed independently. By using common federated learning solutions to allow for collaborative imputation without exposing individual data points, we call it Federated Imputation . Due to the reason of the complexity of the problem, it is important to have a benchmarking tool to rapidly evaluate the performance of federated imputation algorithms under different missing data scenarios. FedImpute is designed to address this need.","title":"Missing Data Imputation of Federated Datasets"},{"location":"overview/#features-of-fedimpute","text":"Flexible Missing Data Simulation : Provide flexible API to simulate missing data scenarios under various missing data distribution and data partition strategies. Built-in Federated Imputation Methods : Supports multiple imputation techniques, including mean, and model-based approaches, tailored for distributed data. Easy Integration : Designed to be easily extended with federated imputation algorithms and workflows. Customizability : Offers extensive configuration options to adapt the imputation process to specific needs.","title":"Features of FedImpute"},{"location":"overview/#architecture-and-components","text":"FedImpute is built on top of the following components: Federated Missing Data Scenario Simulation , Federated Imputation Execution Environment , and Evaluation . Federated Missing Data Scenario Simulation : This component simulates missing data scenarios under various missing data distribution and data partition strategies. Federated Imputation Execution Environment : This component executes federated imputation algorithms on the simulated missing data scenarios. Evaluation : This component evaluates the imputation outcomes and provides insights into the performance of the imputation algorithms.","title":"Architecture and Components"},{"location":"overview/#license","text":"FedImpute is released under the GPL v3.0 License, allowing free use, modification, and distribution of the software. This license encourages open collaboration by permitting the incorporation of this package into both open and closed-source projects.","title":"License"},{"location":"api/fed_impute/","text":"","title":"Federated imputation"},{"location":"api/simulation/","text":"","title":"Scenario simulation"},{"location":"tutorial/basic_usage/","text":"","title":"Basic Usage"},{"location":"user-guide/data_prep/","text":"Dataset and Preprocessing The first step for using FedImpute is to prepare the data. Input Data Format and Preprocessing The data should be in the form of a numpy array ( <np.ndarray> ), where each row represents an observation and each column represents a feature. It will be the input to the simulation process, where it will be partitioned into subset as local dataset for each party and the missing data will be introduced. Required Preprocessing Steps There are some basic preprocessing steps that you need to follow before using FedImpute, The final dataset should be in the form of a numpy array with the columns ordered as follows format: | --------------------- | ------------------ | ------ | | numerical features... | binary features... | target | | --------------------- | ------------------ | ------ | | 0.1 3 5 ... | 1 0 1 0 0 0 | ... | ... | 0.5 10 1 ... | 0 0 1 0 0 1 | ... | | --------------------- | ------------------ | ------ | Ordering Features To facilitate the ease of use for FedImpute, you have to order the features in the dataset such that the numerical features are placed first, followed by the binary features . The target variable should be the last column in the dataset. One-hot Encoding Categorical Features Currently, FedImpute only supports numerical and binary features, does not support categorical features in the dataset. So you have to one-hot encode the categorical features into binary features before using FedImpute. Data Normalization (Optional) It is recommended to normalize the numerical features in the dataset within range of 0 and 1. Helper Functions for Preprocessing FedImpute provides several helper functions to perform the required preprocessing steps. Example of the helper functions are as follows: from fedimpute.data_prep.helper import ordering_features, one_hot_encoding # Example for data with numpy array data = ... data = ordering_features(data, numerical_cols=[0, 1, 3, 4, 8], target_col=-1) data = one_hot_encoding(data, numerical_cols_num=5, max_cateogories=10) # Example data with pandas dataframe data = ... data = ordering_features( data, numerical_cols=['age', 'income', 'height', 'weight', 'temperature'], target_col='house_price' ) data = one_hot_encoding(data, numerical_cols_num=5, max_cateogories=10) ordering_features(data, numerical_cols: List[str or int], target_col: int or str) : This function will order the features in the dataset such that the numerical features are placed first, followed by the binary features. The target variable should be the last column in the dataset. one_hot_encoding(data, numerical_cols_num: int) : This function will one-hot encode the categorical features into binary features. It assumes you data is already orderd as numerical cols + cat_cols + target, so You just need to specify the number of numerical columns. Note : The ordering_features function is required to be called before the one_hot_encoding function. We also provide a one-for-all function to perform all the preprocessing steps at once. from fedimpute.data_prep import prep_data data = ... data = prep_data( data, numerical_cols=['age', 'income', 'height', 'weight', 'temperature'], target_col='house_price' ) Data Configuration Dictionary To allow FedImpute to understand the data and the task type, you need to provide a configuration dictionary called data_config . The example of the data_config dictionary is as follows: data_config = { 'target': 'house_price', 'task_type': 'classification', 'clf_type': 'binary', 'num_cols': 10, } The data_config dictionary should contain the following keys: target : The target variable name. task_type : The task type of the target variable. It can be either classification or regression . clf_type : The classification type of the target variable. It can be either binary or multi-class for classification task. And set it to None for the regression task. num_cols : The number of columns which are numerical (continous variable).","title":"Data Preparation"},{"location":"user-guide/data_prep/#dataset-and-preprocessing","text":"The first step for using FedImpute is to prepare the data.","title":"Dataset and Preprocessing"},{"location":"user-guide/data_prep/#input-data-format-and-preprocessing","text":"The data should be in the form of a numpy array ( <np.ndarray> ), where each row represents an observation and each column represents a feature. It will be the input to the simulation process, where it will be partitioned into subset as local dataset for each party and the missing data will be introduced.","title":"Input Data Format and Preprocessing"},{"location":"user-guide/data_prep/#required-preprocessing-steps","text":"There are some basic preprocessing steps that you need to follow before using FedImpute, The final dataset should be in the form of a numpy array with the columns ordered as follows format: | --------------------- | ------------------ | ------ | | numerical features... | binary features... | target | | --------------------- | ------------------ | ------ | | 0.1 3 5 ... | 1 0 1 0 0 0 | ... | ... | 0.5 10 1 ... | 0 0 1 0 0 1 | ... | | --------------------- | ------------------ | ------ |","title":"Required Preprocessing Steps"},{"location":"user-guide/data_prep/#ordering-features","text":"To facilitate the ease of use for FedImpute, you have to order the features in the dataset such that the numerical features are placed first, followed by the binary features . The target variable should be the last column in the dataset.","title":"Ordering Features"},{"location":"user-guide/data_prep/#one-hot-encoding-categorical-features","text":"Currently, FedImpute only supports numerical and binary features, does not support categorical features in the dataset. So you have to one-hot encode the categorical features into binary features before using FedImpute.","title":"One-hot Encoding Categorical Features"},{"location":"user-guide/data_prep/#data-normalization-optional","text":"It is recommended to normalize the numerical features in the dataset within range of 0 and 1.","title":"Data Normalization (Optional)"},{"location":"user-guide/data_prep/#helper-functions-for-preprocessing","text":"FedImpute provides several helper functions to perform the required preprocessing steps. Example of the helper functions are as follows: from fedimpute.data_prep.helper import ordering_features, one_hot_encoding # Example for data with numpy array data = ... data = ordering_features(data, numerical_cols=[0, 1, 3, 4, 8], target_col=-1) data = one_hot_encoding(data, numerical_cols_num=5, max_cateogories=10) # Example data with pandas dataframe data = ... data = ordering_features( data, numerical_cols=['age', 'income', 'height', 'weight', 'temperature'], target_col='house_price' ) data = one_hot_encoding(data, numerical_cols_num=5, max_cateogories=10) ordering_features(data, numerical_cols: List[str or int], target_col: int or str) : This function will order the features in the dataset such that the numerical features are placed first, followed by the binary features. The target variable should be the last column in the dataset. one_hot_encoding(data, numerical_cols_num: int) : This function will one-hot encode the categorical features into binary features. It assumes you data is already orderd as numerical cols + cat_cols + target, so You just need to specify the number of numerical columns. Note : The ordering_features function is required to be called before the one_hot_encoding function. We also provide a one-for-all function to perform all the preprocessing steps at once. from fedimpute.data_prep import prep_data data = ... data = prep_data( data, numerical_cols=['age', 'income', 'height', 'weight', 'temperature'], target_col='house_price' )","title":"Helper Functions for Preprocessing"},{"location":"user-guide/data_prep/#data-configuration-dictionary","text":"To allow FedImpute to understand the data and the task type, you need to provide a configuration dictionary called data_config . The example of the data_config dictionary is as follows: data_config = { 'target': 'house_price', 'task_type': 'classification', 'clf_type': 'binary', 'num_cols': 10, } The data_config dictionary should contain the following keys: target : The target variable name. task_type : The task type of the target variable. It can be either classification or regression . clf_type : The classification type of the target variable. It can be either binary or multi-class for classification task. And set it to None for the regression task. num_cols : The number of columns which are numerical (continous variable).","title":"Data Configuration Dictionary"},{"location":"user-guide/evaluation/","text":"","title":"Evaluation of Imputation Outcome"},{"location":"user-guide/extend_guide/","text":"","title":"Extend guide"},{"location":"user-guide/fed_imp/","text":"","title":"Federated Imputation"},{"location":"user-guide/scenario_simulation/","text":"","title":"Federated Missing Data Scenario Simulation"}]}